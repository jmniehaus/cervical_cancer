{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schiller test --> iodine that stains different on abnormal cells on cervix\n",
    "# hinsellman --> coloscopy using scope on cervix\n",
    "# cytology --> pap smear\n",
    "# biopsy --> biopsy \n",
    "# These indicate the RESULTS of these tests, assuming they were carried out. 1 means suspect screening, 0 means okay screening. \n",
    "\n",
    "# dx columns mean previous cervical diagnosis \n",
    "# stds_number is the sum over all std columns\n",
    "# Cant figure out what stds_n_diagnosis is, though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay, PrecisionRecallDisplay, fbeta_score, make_scorer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import miceforest as mf\n",
    "from miceforest import mean_match_default\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "import inspect \n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from tempfile import mkdtemp\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "from mice_imputer import *\n",
    "import prince as pr\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"?\": pd.NA})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename columns to be more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = df.columns \n",
    "to_rep = {\n",
    "    \"Number\" : \"n\",\n",
    "    \"Contraceptives\" : \"bc\", \n",
    "    \"Num\" : \"n\",\n",
    "    \"-\" : \"_\",\n",
    "    \"of\" : \"\",\n",
    "    \" \" : \"_\", \n",
    "    \"(\" : \"\",\n",
    "    \")\" : \"\",\n",
    "    \"/\" : \"_\",\n",
    "    \":\" : \"_\", \n",
    "    \"__\" : \"_\"\n",
    "}\n",
    "\n",
    "for key, value in to_rep.items(): \n",
    "    new_names = new_names.str.replace(key, value, regex = True)\n",
    "\n",
    "new_names = new_names.str.lower()\n",
    "\n",
    "df = df.set_axis(new_names, axis = 1)\n",
    "\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, axis = 1).convert_dtypes() # convert_dtypes not working without the apply() call. Probably due to the earlier replace statement, but fiddled for an hour and no dice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifies that the count of stds is the sum over all std columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[df.columns.str.startswith(\"stds_\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all((df[df.columns[df.columns.str.startswith(\"stds_\")]].drop([\"stds_time_since_first_diagnosis\", \"stds_time_since_last_diagnosis\", \"stds_n_diagnosis\", \"stds_number\"], axis = 1).sum(axis = 1) == df.stds_number).dropna())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop n_diagnosis col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"stds_n_diagnosis\"], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missingness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().mean().sort_values(ascending = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop time since std diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns.values[df.columns.str.startswith(\"stds_time\")], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = df.nunique() == 1\n",
    "\n",
    "if any(const):\n",
    "    print(\"Deleting constant columns: {}\".format(df.columns.values[const]))\n",
    "    df.drop(df.columns.values[const], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iud/smoking years are always >0 if you have an IUD/smoke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any((df.iud == 1) & (df.iud_years == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any((df.smokes == 1) & (df.smokes_years == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on STD Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = df[df.columns.values[df.columns.str.startswith(\"stds_\")]].drop(\"stds_number\", axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pc = PCA()\n",
    "stds_s = scaler.fit_transform(stds)\n",
    "pc.fit(stds_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = pc.explained_variance_ratio_\n",
    "eigs_cum = np.cumsum(eigs)\n",
    "ind = [i + 1 for i in range(len(eigs))]\n",
    "print(eigs_cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ind, eigs)\n",
    "plt.plot(ind, eigs_cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.explained_variance_[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pc.components_[0:6].T * np.sqrt(pc.explained_variance_[0:6])\n",
    "\n",
    "loadmat = pd.DataFrame(np.round(loadings, 4), columns=['PC1', 'PC2', 'PC3', \"PC4\", \"PC5\", \"PC6\"], index=stds.columns.values)\n",
    "loadmat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([\"smokes\", \"hormonal_bc\", \"iud\", \"stds\", \"schiller\", \"biopsy\", \"hinselmann\"], axis = 1)\n",
    "x[\"n_stds\"] = x[\"stds_number\"]\n",
    "x.drop(\"stds_number\", axis = 1, inplace = True)\n",
    "#x.drop(x.columns.values[x.columns.str.startswith(\"stds\")], axis = 1, inplace = True)\n",
    "y = df[[\"biopsy\"]].astype(\"int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x.select_dtypes(include=['Int64', 'Float64']).columns.values] = x.select_dtypes(include=['Int64', 'Float64']).astype('float')\n",
    "# x[x.columns.values[x.columns.str.startswith(\"stds_\")]] = x[x.columns.values[x.columns.str.startswith(\"stds_\")]].astype(\"bool\")\n",
    "# x[x.columns.values[x.columns.str.startswith(\"dx\")]] = x[x.columns.values[x.columns.str.startswith(\"dx\")]].astype(\"bool\")\n",
    "# x[\"citology\"] = x.citology.astype(\"bool\")\n",
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 987417)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.stds_condylomatosis.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape, y_test.shape)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "p = .0075\n",
    "# x = stats.nbinom.rvs(n = n, p=p, size = 10000)\n",
    "# plt.hist(x,density=True, bins = 100)\n",
    "xl = np.floor(np.linspace(0, 1000, 1000))\n",
    "plt.plot(xl, stats.nbinom.pmf(xl, n = n, p = p, loc = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((stats.nbinom.rvs(size = 10000, n = n, p = p, loc = 1))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = np.linspace(0, 1, 1000)\n",
    "plt.plot(xl, stats.beta.pdf(xl, 1.75, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(objective = \"binary\", class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_grid_template = {\n",
    "    \"objective\" : \"poisson\"\n",
    "}\n",
    "\n",
    "impute_grid= {}\n",
    "\n",
    "keys = x.columns.values[x.isna().any()] \n",
    "\n",
    "for i in keys: \n",
    "\n",
    "    impute_grid[i] = impute_grid_template.copy()\n",
    "\n",
    "    if \"stds_\" in i: \n",
    "        impute_grid[i][\"objective\"] = \"binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_match = mean_match_default.copy()\n",
    "mean_match.set_mean_match_candidates(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds_indicator = ColumnTransformer(\n",
    "    [(\"indicator\", MissingIndicator(), [\"stds_hpv\"])],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "simple_union = FeatureUnion(\n",
    "    transformer_list=[\n",
    "         ('features', SimpleImputer(strategy='median')),\n",
    "         ('indicator', stds_indicator)]\n",
    ")\n",
    "\n",
    "mice_union = FeatureUnion(\n",
    "    transformer_list=[\n",
    "         ('features', mice_imputer(mean_match_scheme = mean_match)),\n",
    "         ('indicator', stds_indicator)]\n",
    ")\n",
    "\n",
    "std_cols = np.where(df.columns.str.startswith(\"stds\"))[0]\n",
    "\n",
    "pca_stds = ColumnTransformer(\n",
    "    [(\"pca\", PCA(n_components = 5),  std_cols)],\n",
    "    remainder = \"passthrough\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "pipe = Pipeline(\n",
    "    memory = memory,\n",
    "    steps = [\n",
    "        (\"imputer\", simple_union),\n",
    "        (\"pca\", pca_stds),\n",
    "        (\"classifier\", clf)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [\n",
    "    {\n",
    "    \"imputer\" : [simple_union],\n",
    "    \"imputer__features__strategy\" : [\"mean\", \"median\"],\n",
    "    \"pca__pca__n_components\" : stats.randint(1, 8),\n",
    "    \"classifier__n_estimators\" : stats.nbinom(n = 2, p = .0075, loc = 1),\n",
    "    \"classifier__max_depth\" : stats.randint(1, 10),\n",
    "    \"classifier__learning_rate\" : stats.beta(1.5, 9),\n",
    "    \"classifier__min_child_samples\" : stats.randint(3, 75),\n",
    "    \"classifier__cat_smooth\" : stats.uniform(0, 25)\n",
    "    },\n",
    "    {\"imputer\" : [mice_union],\n",
    "    \"pca__pca__n_components\" : stats.randint(1, 8),\n",
    "    \"classifier__n_estimators\" : stats.nbinom(n = 2, p = .0075, loc = 1),\n",
    "    \"classifier__max_depth\" : stats.randint(1, 10),\n",
    "    \"classifier__learning_rate\" : stats.beta(1.5, 9),\n",
    "    \"classifier__min_child_samples\" : stats.randint(3, 75),\n",
    "    \"classifier__cat_smooth\" : stats.uniform(0, 25),\n",
    "    \"imputer__features__mice_iterations\" : stats.randint(5, 20),\n",
    "    \"imputer__features__lgb_iterations\" : stats.nbinom(n = 2, p = .0075, loc = 1),\n",
    "    \"imputer__features__lgb_learning_rate\" : stats.beta(1.75, 8),\n",
    "    \"imputer__features__lgb_max_depth\" : stats.randint(1, 10),\n",
    "    \"imputer__features__lgb_cat_smooth\" : stats.uniform(0, 25),\n",
    "    \"imputer__features__lgb_feature_fraction_bynode\" : stats.uniform(0, 1)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = StratifiedKFold(n_splits=5, random_state=874841, shuffle = True)\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=878571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_scorer = make_scorer(fbeta_score, beta = 3)\n",
    "\n",
    "rcv = RandomizedSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_distributions = grid, \n",
    "    scoring = \"recall\",\n",
    "    refit = True, \n",
    "    cv = inner_cv,\n",
    "    return_train_score = True,\n",
    "    n_jobs = 1,\n",
    "    n_iter = 2000,\n",
    "    random_state = 97417\n",
    ")\n",
    "\n",
    "nested_scores = cross_validate(\n",
    "    rcv, \n",
    "    X = x, \n",
    "    y = y.values.flatten(), \n",
    "    cv = outer_cv, \n",
    "    return_estimator = True, \n",
    "    scoring = [\"average_precision\", \"balanced_accuracy\", \"f1\", \"precision\", \"recall\"],\n",
    "    n_jobs = 19,\n",
    "    verbose = 999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rmtree(cachedir)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(nested_scores, \"~/gdrive/github/cervical_cancer/rcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_models = nested_scores['estimator']\n",
    "# mn = nested_scores[\"test_score\"].mean()\n",
    "# st = nested_scores[\"test_score\"].std()\n",
    "# [mn - 1.96*st, mn + 1.96 * st]\n",
    "#for i, model in enumerate(best_models):\n",
    "#     #print(model.best_estimator_)\n",
    "      #print(model.best_params_)\n",
    "#     print(model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cervical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36a4d8ebaadf09211e7ea3eda12f34cb65c6aa2c0258225f56eef2ad8727d175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
