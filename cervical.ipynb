{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schiller test --> iodine that stains different on abnormal cells on cervix\n",
    "# hinsellman --> coloscopy using scope on cervix\n",
    "# cytology --> pap smear\n",
    "# biopsy --> biopsy \n",
    "# These indicate the RESULTS of these tests, assuming they were carried out. 1 means suspect screening, 0 means okay screening. \n",
    "\n",
    "# dx columns mean previous cervical diagnosis \n",
    "# stds_number is the sum over all std columns\n",
    "# Cant figure out what stds_n_diagnosis is, though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay, PrecisionRecallDisplay, fbeta_score, make_scorer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import miceforest as mf\n",
    "from miceforest import mean_match_default\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "import inspect \n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from tempfile import mkdtemp\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "from mice_imputer import *\n",
    "from missing_transformer import *\n",
    "import prince as pr\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00383/risk_factors_cervical_cancer.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"?\": pd.NA})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename columns to be more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = df.columns \n",
    "to_rep = {\n",
    "    \"Number\" : \"n\",\n",
    "    \"Contraceptives\" : \"bc\", \n",
    "    \"Num\" : \"n\",\n",
    "    \"-\" : \"_\",\n",
    "    \"of\" : \"\",\n",
    "    \" \" : \"_\", \n",
    "    \"(\" : \"\",\n",
    "    \")\" : \"\",\n",
    "    \"/\" : \"_\",\n",
    "    \":\" : \"_\", \n",
    "    \"__\" : \"_\"\n",
    "}\n",
    "\n",
    "for key, value in to_rep.items(): \n",
    "    new_names = new_names.str.replace(key, value, regex = True)\n",
    "\n",
    "new_names = new_names.str.lower()\n",
    "\n",
    "df = df.set_axis(new_names, axis = 1)\n",
    "\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, axis = 1).convert_dtypes() # convert_dtypes not working without the apply() call. Probably due to the earlier replace statement, but fiddled for an hour and no dice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic variable description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iud/smoking/HBC years are always >0 if you have IUD/smoke/HBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_zerotrunc(df, bin_col, yr_col):\n",
    "    return np.any((df[bin_col] == 1) & (df[yr_col] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = [\"iud\", \"smokes\", \"hormonal_bc\"]\n",
    "yr_cols = [\"iud_years\", \"smokes_years\", \"hormonal_bc_years\"]\n",
    "\n",
    "for bin, yr in zip(bin_cols, yr_cols):\n",
    "    print(f\"{bin} == 1 when {yr} == 0?\", check_zerotrunc(df, bin, yr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Years variables are not strictly integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df % 1 == 0\n",
    "df_mod.all(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the count of stds is linear combination of all std columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all((df[df.columns[df.columns.str.startswith(\"stds_\")]].drop([\"stds_time_since_first_diagnosis\", \"stds_time_since_last_diagnosis\", \"stds_n_diagnosis\", \"stds_number\"], axis = 1).sum(axis = 1) == df.stds_number).dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop time since std diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns.values[df.columns.str.startswith(\"stds_time\")], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for/drop constant/near-constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = df.nunique() == 1\n",
    "if any(const):\n",
    "    print(\"Deleting constant columns: {}\".format(df.columns.values[const]))\n",
    "    df.drop(df.columns.values[const], axis = 1, inplace = True)\n",
    "\n",
    "# near_const = df.sum(axis = 0) <= 18\n",
    "# if any(near_const): \n",
    "#     print(f\"\\nDeleting near-constant columns: {df.columns.values[near_const]}\")\n",
    "#     df.drop(df.columns.values[near_const], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop n_diagnosis col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"stds_n_diagnosis\"], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "cols = corr.columns\n",
    "\n",
    "sns.heatmap(\n",
    "    corr, \n",
    "    xticklabels = cols,\n",
    "    yticklabels = cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_hist = [\"age\", \"n_sexual_partners\", \"first_sexual_intercourse\", \"n_pregnancies\", \"smokes_packs_year\", \"hormonal_bc_years\"]\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 3)\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "for ax, var in zip(axs.ravel(), to_hist): \n",
    "    df[var].plot.hist(bins = 15, ax = ax, title = var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop([\"smokes\", \"hormonal_bc\", \"iud\", \"stds\", \"schiller\", \"biopsy\", \"hinselmann\"], axis = 1)\n",
    "x[\"n_stds\"] = x[\"stds_number\"]\n",
    "x.drop(\"stds_number\", axis = 1, inplace = True)\n",
    "y = df[[\"biopsy\"]].astype(\"int64\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have to have cat/float/int dtypes for lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x.select_dtypes(include=['Int64', 'Float64']).columns.values] = x.select_dtypes(include=['Int64', 'Float64']).astype('float')\n",
    "x.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(objective = \"binary\", is_unbalance = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some useful fixed parameters for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "    \"objective\" : \"regression\"\n",
    "}\n",
    "\n",
    "varparms = {}\n",
    "\n",
    "keys = x.columns.values[x.isna().any()] \n",
    "\n",
    "for i in keys: \n",
    "\n",
    "    varparms[i] = template.copy()\n",
    "\n",
    "    if \"stds_\" in i: \n",
    "        varparms[i][\"objective\"] = \"binary\"\n",
    "        varparms[i][\"is_unbalance\"] = True\n",
    "\n",
    "    if (x[i].nunique() > 2) & (np.all(x[i].dropna() % 1 == 0)):\n",
    "        varparms[i][\"objective\"] = \"poisson\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varparms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set predictive mean matching scheme for imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_match = mean_match_default.copy()\n",
    "mean_match.set_mean_match_candidates(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pipeline components, instantiate pipe\n",
    "\n",
    "* Impute missing values, tuning either constant imputation (`simple_union`) or mice imputation (`mice_union`)\n",
    "* Add a single missingness variable for the sexual history related variables, as this constitutes the bulk of the missingness.\n",
    "* Scale everything\n",
    "* Apply PCA to std columns \n",
    "* Train/tune LGBM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_union = FeatureUnion(\n",
    "    transformer_list=[\n",
    "         ('features', SimpleImputer(strategy='median')),\n",
    "         ('indicator', missing_transformer())\n",
    "         ]\n",
    ")\n",
    "\n",
    "mice_union = FeatureUnion(\n",
    "    transformer_list=[\n",
    "         ('features', mice_imputer(mean_match_scheme = mean_match, mice_iterations = 15, variable_parameters = varparms)),\n",
    "         ('indicator', missing_transformer())]\n",
    ")\n",
    "\n",
    "std_cols = np.where(x.columns.str.startswith(\"stds\"))[0]\n",
    "print(std_cols)\n",
    "\n",
    "pca_stds = ColumnTransformer(\n",
    "    [(\"pca\", PCA(n_components = 5),  std_cols)],\n",
    "    remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cachedir = mkdtemp()\n",
    "#memory = Memory(location=cachedir, verbose=0)\n",
    "pipe = Pipeline(\n",
    "    #memory = memory,\n",
    "    steps = [\n",
    "        (\"imputer\", simple_union),\n",
    "        (\"scaler\", scaler),\n",
    "        (\"pca\", pca_stds),\n",
    "        (\"classifier\", clf)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Some) Marginal distributions for random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "p = .0075\n",
    "xl = np.floor(np.linspace(0, 1250, 1250))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "nb = ax.bar(\n",
    "    xl, \n",
    "    stats.nbinom.pmf(xl, n = n, p = p, loc = 1)\n",
    ")\n",
    "ax.set_title(f\"N Estimators Distribution [nbinom(p = {p}, n = {n})]\")\n",
    "ax.set_ylabel(\"Probability Mass\")\n",
    "ax.set_xlabel(\"N Estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = n*(1-p)/p\n",
    "st = np.sqrt(mn*p**-1)\n",
    "ps = [.01, .1, .25, .5, .75, .9, .99]\n",
    "qs = stats.nbinom.ppf(ps, n = n, p = p)\n",
    "qs = {str(p) : q for p,q in zip(ps, qs)}\n",
    "qs[\"mean\"] = mn \n",
    "qs[\"std\"] = st \n",
    "pd.DataFrame(qs, index = [\"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = .3\n",
    "xl = np.linspace(0, 1, 1000)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ex = ax.plot(\n",
    "    xl, \n",
    "    stats.expon.pdf(xl, scale = scale)\n",
    ")\n",
    "ax.set_title(f\"Learning Rate Distribution [expon(scale = {scale})]\")\n",
    "ax.set_ylabel(\"Probability Density\")\n",
    "ax.set_xlabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = scale\n",
    "st = scale\n",
    "ps = [.01, .1, .25, .5, .75, .9, .99]\n",
    "qs = stats.expon.ppf(ps, scale = scale)\n",
    "qs = {str(p) : q for p,q in zip(ps, qs)}\n",
    "qs[\"mean\"] = mn \n",
    "qs[\"std\"] = st \n",
    "pd.DataFrame(qs, index = [\"value\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define random search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_dist = stats.expon(scale = scale)\n",
    "ne_dist = stats.nbinom(n = n, p = p, loc = 1)\n",
    "nl_dist = stats.randint(2, 51)\n",
    "md_dist = stats.randint(1, 10)\n",
    "pc_dist = stats.randint(1, 2)\n",
    "mc_dist = stats.randint(15, 75)\n",
    "\n",
    "base_grid = {\n",
    "    \"pca__pca__n_components\" : pc_dist,\n",
    "    \"classifier__n_estimators\" : ne_dist,\n",
    "    \"classifier__num_leaves\" : nl_dist,\n",
    "    \"classifier__max_depth\" : md_dist,\n",
    "    \"classifier__learning_rate\" : lr_dist,\n",
    "    \"classifier__min_child_samples\" : mc_dist\n",
    "}\n",
    "\n",
    "grid = [\n",
    "    {\n",
    "        \"imputer\" : [simple_union],\n",
    "        \"imputer__features__strategy\" : [\"mean\", \"median\"],\n",
    "        **base_grid\n",
    "    },\n",
    "    {\n",
    "        \"imputer\" : [mice_union],\n",
    "        \"imputer__features__lgb_iterations\" : ne_dist,\n",
    "        \"imputer__features__lgb_learning_rate\" : lr_dist,\n",
    "        \"imputer__features__lgb_max_depth\" : md_dist,\n",
    "        \"imputer__features__lgb_num_leaves\" : nl_dist,\n",
    "        **base_grid\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup nested CV folds, flush RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = StratifiedKFold(n_splits=5, random_state=874841, shuffle = True)\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=878571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model, cleanup, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.columns.values)\n",
    "std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_scorer = make_scorer(fbeta_score, beta = 2)\n",
    "\n",
    "rcv = RandomizedSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_distributions = grid, \n",
    "    scoring = f3_scorer,\n",
    "    refit = True, \n",
    "    cv = inner_cv,\n",
    "    return_train_score = True,\n",
    "    n_jobs = 1,\n",
    "    n_iter = 10,\n",
    "    random_state = 97417\n",
    ")\n",
    "\n",
    "nested_scores = cross_validate(\n",
    "    rcv, \n",
    "    X = x, \n",
    "    y = y.values.flatten(), \n",
    "    cv = outer_cv, \n",
    "    return_estimator = True, \n",
    "    scoring = [\"average_precision\", \"balanced_accuracy\", \"f1\", \"precision\", \"recall\"],\n",
    "    n_jobs = 20,\n",
    "    verbose = 999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rmtree(cachedir)\n",
    "except:\n",
    "    print(\"No cache to remove.\") \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(nested_scores, \"/home/john/gdrive/github/cervical_cancer/rcv.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_models = nested_scores['estimator']\n",
    "# mn = nested_scores[\"test_score\"].mean()\n",
    "# st = nested_scores[\"test_score\"].std()\n",
    "# [mn - 1.96*st, mn + 1.96 * st]\n",
    "#for i, model in enumerate(best_models):\n",
    "#     #print(model.best_estimator_)\n",
    "      #print(model.best_params_)\n",
    "#     print(model.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cervical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36a4d8ebaadf09211e7ea3eda12f34cb65c6aa2c0258225f56eef2ad8727d175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
